{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from skimage.feature import local_binary_pattern\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pic_shape = (200, 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 数据库导入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集长度: 4750 测试集长度: 794\n"
     ]
    }
   ],
   "source": [
    "train_dataset = pickle.load(open('my_train.pkl', 'rb'))\n",
    "test_dataset = pickle.load(open('my_test.pkl', 'rb'))\n",
    "print('训练集长度:', len(train_dataset['data']), '测试集长度:', len(test_dataset['data']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(len(train_dataset['data'])):\n",
    "    img=train_dataset['data'][i]\n",
    "    target=train_dataset['target'][i]\n",
    "    # 翻转增强\n",
    "    train_dataset['data'].append(cv2.flip(img, -1))\n",
    "    train_dataset['target'].append(target)\n",
    "    train_dataset['data'].append(cv2.flip(img, 1))\n",
    "    train_dataset['target'].append(target)\n",
    "\n",
    "    # 旋转增强\n",
    "    # getRotationMatrix2D有三个参数，第一个为旋转中心，第二个为旋转角度，第三个为缩放比例\n",
    "    M = cv2.getRotationMatrix2D((int(pic_shape[0]*0.5),int(pic_shape[1]*0.5)), 45, 1)\n",
    "    dst = cv2.warpAffine(img, M, pic_shape)\n",
    "    train_dataset['data'].append(dst)\n",
    "    train_dataset['target'].append(target)\n",
    "    M = cv2.getRotationMatrix2D((int(pic_shape[0]*0.5),int(pic_shape[1]*0.5)), 90, 1)\n",
    "    dst = cv2.warpAffine(img, M, pic_shape)\n",
    "    train_dataset['data'].append(dst)\n",
    "    train_dataset['target'].append(target)\n",
    "    M = cv2.getRotationMatrix2D((int(pic_shape[0]*0.5),int(pic_shape[1]*0.5)), 135, 1)\n",
    "    dst = cv2.warpAffine(img, M, pic_shape)\n",
    "    train_dataset['data'].append(dst)\n",
    "    train_dataset['target'].append(target)\n",
    "\n",
    "#\n",
    "print('数据拓展结束')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_mask_for_plant(image):\n",
    "    image_hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    sensitivity = 35\n",
    "    lower_hsv = np.array([60 - sensitivity, 100, 50])\n",
    "    upper_hsv = np.array([60 + sensitivity, 255, 255])\n",
    "\n",
    "    mask = cv2.inRange(image_hsv, lower_hsv, upper_hsv)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (11, 11))\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    return mask\n",
    "\n",
    "\n",
    "def segment_plant(image):\n",
    "    mask = create_mask_for_plant(image)\n",
    "    output = cv2.bitwise_and(image, image, mask=mask)\n",
    "    return output\n",
    "\n",
    "\n",
    "def sharpen_image(image):\n",
    "    image_blurred = cv2.GaussianBlur(image, (0, 0), 3)\n",
    "    image_sharp = cv2.addWeighted(image, 1.5, image_blurred, -0.5, 0)\n",
    "    return image_sharp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 特征提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "winSize = pic_shape\n",
    "blockSize = (int(pic_shape[0]*0.2),int(pic_shape[1]*0.2))\n",
    "blockStride = (int(pic_shape[0]*0.2),int(pic_shape[1]*0.2))\n",
    "cellSize = (int(pic_shape[0]*0.1),int(pic_shape[1]*0.1))\n",
    "nbins = 4\n",
    "hog = cv2.HOGDescriptor(winSize, blockSize, blockStride, cellSize, nbins)\n",
    "orb=cv2.ORB_create(nfeatures=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/4750 [00:00<?, ?it/s]<ipython-input-7-7252d8a57b8e>:28: DeprecationWarning: The normed argument is ignored when density is provided. In future passing both will result in an error.\n",
      "  lbp_hist,_=np.histogram(lbp.reshape((-1,)), normed=True, density=True, bins=256, range=(0, max_bins))\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 4750/4750 [00:49<00:00, 96.78it/s]\n",
      "  0%|                                                                                          | 0/794 [00:00<?, ?it/s]<ipython-input-7-7252d8a57b8e>:64: DeprecationWarning: The normed argument is ignored when density is provided. In future passing both will result in an error.\n",
      "  lbp_hist,_ = np.histogram(lbp.reshape((-1,)), normed=True, density=True, bins=256, range=(0, max_bins))\n",
      "  2%|█▏                                                                              | 12/794 [00:00<00:07, 104.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "其中HOG特征维度 (3600,)\n",
      "其中LBP特征维度 (256,)\n",
      "其中ORB特征维度 (1600,)\n",
      "其中GRAY特征维度 (400,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 794/794 [00:07<00:00, 100.28it/s]\n"
     ]
    }
   ],
   "source": [
    "winStride = (8, 8)\n",
    "padding = (8, 8)\n",
    "# 四分割 直方图和词袋模型\n",
    "train_HOG_feature=[]\n",
    "train_ORB_feature=[]\n",
    "train_LBP_feature=[]\n",
    "train_GRAY_feature=[]\n",
    "\n",
    "\n",
    "test_HOG_feature=[]\n",
    "test_ORB_feature=[]\n",
    "test_LBP_feature=[]\n",
    "test_GRAY_feature=[]\n",
    "\n",
    "for img_data in tqdm(train_dataset['data']):\n",
    "    image_segmented = segment_plant(img_data)\n",
    "    image_sharpen = sharpen_image(image_segmented)\n",
    "    gray = cv2.cvtColor(image_sharpen, cv2.COLOR_BGR2GRAY)\n",
    "    # 图像数据生成mask和gray\n",
    "    \n",
    "    #resize后的小型图像\n",
    "    gray_resized=cv2.resize(gray, (20, 20))\n",
    "    train_GRAY_feature.append(gray_resized.reshape((-1,)))\n",
    "    \n",
    "    # lbp统计直方图\n",
    "    lbp = local_binary_pattern(gray,P=8,R=3)\n",
    "    max_bins=lbp.max()\n",
    "    lbp_hist,_=np.histogram(lbp.reshape((-1,)), normed=True, density=True, bins=256, range=(0, max_bins))\n",
    "    train_LBP_feature.append(lbp_hist)\n",
    "    #\n",
    "    # orb特征\n",
    "    ORB_zero=np.zeros((50,32))\n",
    "    kp1, des1 = orb.detectAndCompute(gray, None)\n",
    "    try:\n",
    "        ORB=np.pad(des1,((0,50-des1.shape[0]),(0,0)),'constant')\n",
    "    except:\n",
    "        ORB=np.zeros((50,32))\n",
    "    assert ORB.shape==(50,32)\n",
    "    train_ORB_feature.append(ORB.reshape((-1,)))\n",
    "    # hog特征\n",
    "    #hog_result = hog.compute(image_sharpen, winStride, padding).reshape((-1,))\n",
    "    hog_result = hog.compute(gray, winStride, padding).reshape((-1,))\n",
    "    train_HOG_feature.append(hog_result)\n",
    "\n",
    "print('其中HOG特征维度',train_HOG_feature[0].shape)\n",
    "print('其中LBP特征维度',train_LBP_feature[0].shape)\n",
    "print('其中ORB特征维度',train_ORB_feature[0].shape)\n",
    "print('其中GRAY特征维度',train_GRAY_feature[0].shape)\n",
    "\n",
    "\n",
    "for img_data in tqdm(test_dataset['data']):\n",
    "    image_segmented = segment_plant(img_data)\n",
    "    image_sharpen = sharpen_image(image_segmented)\n",
    "    gray = cv2.cvtColor(image_sharpen, cv2.COLOR_BGR2GRAY)\n",
    "    # 图像数据生成mask和gray\n",
    "\n",
    "    #resize后的小型图像\n",
    "    gray_resized=cv2.resize(gray, (20, 20))\n",
    "    test_GRAY_feature.append(gray_resized.reshape((-1,)))\n",
    "    \n",
    "    # lbp统计直方图\n",
    "    lbp = local_binary_pattern(gray,P=8,R=3)\n",
    "    max_bins = lbp.max()\n",
    "    lbp_hist,_ = np.histogram(lbp.reshape((-1,)), normed=True, density=True, bins=256, range=(0, max_bins))\n",
    "    test_LBP_feature.append(lbp_hist)\n",
    "    #\n",
    "    # orb特征\n",
    "\n",
    "    kp1, des1 = orb.detectAndCompute(gray, None)\n",
    "    try:\n",
    "        ORB=np.pad(des1,((0,50-des1.shape[0]),(0,0)),'constant')\n",
    "    except:\n",
    "        ORB=np.zeros((50,32))\n",
    "    assert ORB.shape==(50,32)\n",
    "    test_ORB_feature.append(ORB.reshape((-1,)))\n",
    "    # hog特征\n",
    "    #hog_result = hog.compute(image_sharpen, winStride, padding).reshape((-1,))\n",
    "    hog_result = hog.compute(gray, winStride, padding).reshape((-1,))\n",
    "    test_HOG_feature.append(hog_result)\n",
    "# 特征提取\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "特征归一化完成\n"
     ]
    }
   ],
   "source": [
    "# 特征归一化\n",
    "\n",
    "train_mm_HOG = preprocessing.MinMaxScaler()\n",
    "train_mm_HOG_data = train_mm_HOG.fit_transform(train_HOG_feature)\n",
    "train_HOG_feature = train_mm_HOG.inverse_transform(train_mm_HOG_data)\n",
    "\n",
    "train_mm_LBP = preprocessing.MinMaxScaler()\n",
    "train_mm_LBP_data = train_mm_LBP.fit_transform(train_LBP_feature)\n",
    "train_LBP_feature = train_mm_LBP.inverse_transform(train_mm_LBP_data)\n",
    "\n",
    "train_mm_ORB = preprocessing.MinMaxScaler()\n",
    "train_mm_ORB_data = train_mm_ORB.fit_transform(train_ORB_feature)\n",
    "train_ORB_feature = train_mm_ORB.inverse_transform(train_mm_ORB_data)\n",
    "\n",
    "train_mm_GRAY = preprocessing.MinMaxScaler()\n",
    "train_mm_GRAY_data = train_mm_GRAY.fit_transform(train_GRAY_feature)\n",
    "train_GRAY_feature = train_mm_GRAY.inverse_transform(train_mm_GRAY_data)\n",
    "\n",
    "\n",
    "test_mm_HOG = preprocessing.MinMaxScaler()\n",
    "test_mm_HOG_data = test_mm_HOG.fit_transform(test_HOG_feature)\n",
    "test_HOG_feature = test_mm_HOG.inverse_transform(test_mm_HOG_data)\n",
    "\n",
    "test_mm_LBP = preprocessing.MinMaxScaler()\n",
    "test_mm_LBP_data = test_mm_LBP.fit_transform(test_LBP_feature)\n",
    "test_LBP_feature = test_mm_LBP.inverse_transform(test_mm_LBP_data)\n",
    "\n",
    "test_mm_ORB = preprocessing.MinMaxScaler()\n",
    "test_mm_ORB_data = test_mm_ORB.fit_transform(test_ORB_feature)\n",
    "test_ORB_feature = test_mm_ORB.inverse_transform(test_mm_ORB_data)\n",
    "\n",
    "test_mm_GRAY = preprocessing.MinMaxScaler()\n",
    "test_mm_GRAY_data = test_mm_GRAY.fit_transform(test_GRAY_feature)\n",
    "test_GRAY_feature = test_mm_GRAY.inverse_transform(test_mm_GRAY_data)\n",
    "\n",
    "print('特征归一化完成')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train综合特征维度 (4750, 5456)\n",
      "test综合特征维度 (794, 5456)\n",
      "特征提取结束\n"
     ]
    }
   ],
   "source": [
    "# 特征融合\n",
    "\n",
    "# train_feature=np.hstack([np.array(train_HOG_feature),np.array(train_LBP_feature),np.array(train_ORB_feature),np.array(train_GRAY_feature)])\n",
    "# test_feature=np.hstack([np.array(test_HOG_feature),np.array(test_LBP_feature),np.array(test_ORB_feature),np.array(test_GRAY_feature)])\n",
    "train_feature=np.hstack([np.array(train_HOG_feature),np.array(train_LBP_feature),np.array(train_ORB_feature)])\n",
    "test_feature=np.hstack([np.array(test_HOG_feature),np.array(test_LBP_feature),np.array(test_ORB_feature)])\n",
    "# train_feature=np.hstack([np.array(train_HOG_feature),np.array(train_ORB_feature)])\n",
    "# test_feature=np.hstack([np.array(test_HOG_feature),np.array(test_ORB_feature)])\n",
    "# train_feature=np.array(train_ORB_feature)\n",
    "# test_feature=np.array(test_ORB_feature)\n",
    "# train_feature=np.array(train_HOG_feature)\n",
    "# test_feature=np.array(test_HOG_feature)\n",
    "print('train综合特征维度', train_feature.shape)\n",
    "print('test综合特征维度', test_feature.shape)\n",
    "print('特征提取结束')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import KernelPCA\n",
    "#数据降维\n",
    "print('数据降维开始')\n",
    "n_components=2000\n",
    "train_len=len(train_feature)\n",
    "data=np.vstack([train_feature,test_feature])\n",
    "# pca_tsne = TSNE(n_components=n_components)\n",
    "# newData = pca_tsne.fit_transform(data)\n",
    "sklearn_kpca = KernelPCA(n_components=n_components, kernel=\"rbf\", gamma=15)\n",
    "newData = sklearn_kpca.fit_transform(data)\n",
    "print(newData.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# train_feature=newData[0:train_len]\n",
    "# assert train_len==len(train_feature)\n",
    "# test_feature=newData[train_len:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# #特征数据存储\n",
    "# train_feature_dist=train_dataset.copy()\n",
    "# train_feature_dist['data']=train_feature\n",
    "# pickle.dump(train_feature_dist,open('/Users/mataoxun/code/python/pythonProject3/train_feature.pkl','wb'))\n",
    "# test_feature_dist=test_dataset.copy()\n",
    "# test_feature_dist['data']=test_feature\n",
    "# pickle.dump(test_feature_dist,open('/Users/mataoxun/code/python/pythonProject3/test_feature.pkl','wb'))\n",
    "# print('特征数据存储结束')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xgboost分类开始\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anacoda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08:58:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "测试集分类预测结束\n"
     ]
    }
   ],
   "source": [
    "# # SVM分类\n",
    "# from sklearn import svm\n",
    "# print('SVM分类开始')\n",
    "# model = svm.SVC()\n",
    "# model.fit(train_feature, train_dataset['target'])\n",
    "# predicted = model.predict(test_feature)\n",
    "\n",
    "# 随机森林分类\n",
    "# print('随机森林分类开始')\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# model = RandomForestClassifier()\n",
    "# model.fit(train_feature, train_dataset['target'])\n",
    "# predicted = model.predict(test_feature)\n",
    "#\n",
    "\n",
    "#XGBoost分类\n",
    "print('Xgboost分类开始')\n",
    "from xgboost import XGBClassifier\n",
    "model = XGBClassifier(max_depth=5)\n",
    "model.fit(train_feature, train_dataset['target'])\n",
    "predicted = model.predict(test_feature)\n",
    "\n",
    "\n",
    "print('测试集分类预测结束')\n",
    "# from sklearn.model_selection import KFold, cross_val_score\n",
    "# def f1_kf(my_model):\n",
    "#     kf = KFold(5, shuffle=True, random_state=50).get_n_splits(train_feature)\n",
    "#     result_list= np.sqrt(-cross_val_score(my_model, train_feature, train_dataset['target'], scoring=\"f1\", cv = kf))\n",
    "#     return(result_list)\n",
    "# f1_kf(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 结果生成\n",
    "sub=pd.read_csv('sample_submission.csv')\n",
    "sub['file'] = test_dataset['file_name']\n",
    "sub['species'] = list(map(lambda x:train_dataset['dict'][x], predicted))\n",
    "sub.to_csv('submission.csv', index=False)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
